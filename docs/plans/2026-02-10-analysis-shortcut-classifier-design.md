# Analysis Shortcut Query Classifier

## Problem

The analysis shortcut in `repo.py` is over-eager. When a user asks a question, it tries to answer from the pre-generated codebase analysis even when the analysis cannot possibly answer the question. Two failure modes:

1. **Absence treated as evidence**: User asks "SECURITY.md?" — the analysis doesn't mention it, so the LLM says "not found in analysis." The user hears "not in the repo," but SECURITY.md exists; it's just not in the summary.

2. **Ignoring conversational doubt**: User says "How accurate is it? I think it's out of date" — the shortcut answers from analysis again, saying "it appears up-to-date," when the user explicitly wants verification against actual files.

Both stem from the same root: the shortcut doesn't distinguish between questions the analysis can positively answer and questions where the analysis's silence or summary-level coverage is insufficient.

## Solution

Add a lightweight LLM classifier as a pre-filter before the shortcut attempt. The classifier categorizes the query and skips the shortcut entirely for query types that inherently need file access.

### Query categories that bypass the shortcut

1. **Existence checks** — "does X exist?", "is there a Y?"
2. **Accuracy/correctness verification** — "how accurate is X?", "is X out of date?"
3. **User doubt/disagreement** — "I think it's wrong", "are you sure?"
4. **Questions needing specific file contents** — "what's in the Makefile?", "show me the config"

### Classifier design

New function `classify_query(question, model, api_key) -> bool` in `src/shesha/analysis/shortcut.py`:

- Makes a single LLM call using the same model as the shortcut
- Receives `question_with_history` (conversation history included) so it can detect follow-up doubt
- Does NOT receive the analysis context (keeps token cost low)
- Returns `True` (try shortcut) or `False` (skip to RLM)
- Returns `True` on any exception or unparseable output (graceful fallback)

### Classifier prompt

The prompt explicitly describes what the analysis contains and doesn't contain, so the classifier knows the analysis scope:

```
You are a query classifier. Given a user question about a codebase,
determine whether a high-level codebase summary could answer it, or whether
it requires access to actual source files.

The summary contains ONLY:
- A 2-3 sentence overview of the project's purpose
- Major components (name, path, description, public APIs, data models, entry points)
- External dependencies (name, type, description)

It does NOT contain individual file listings, file contents, README/docs text,
test details, CI config, or any non-component files.

Respond with exactly one word:
- ANALYSIS_OK — if the question can be answered from the above
- NEED_DEEPER — if the question involves ANY of:
  * Checking whether a specific file or artifact exists
  * Verifying accuracy or correctness of any documentation or prior answer
  * The user expressing doubt, disagreement, or correction
  * Reading, inspecting, or quoting specific file contents
  * Anything not covered by the summary's scope
```

### Integration flow

```
query → classify_query() → False? → return None (fall through to RLM)
                          → True?  → existing shortcut logic (which itself may return NEED_DEEPER)
```

The gate is entirely within `try_answer_from_analysis` in `shortcut.py`. No changes to the TUI app, the existing shortcut prompt, `examples/repo.py`, or `script_utils.py`.

## What the analysis actually contains

The analysis is generated by `src/shesha/analysis/prompts/generate.md` and stored as a `RepoAnalysis` with:

- `overview`: 2-3 sentence project summary
- `components[]`: name, path, description, APIs (REST/GraphQL/gRPC/CLI/events), models, entry_points, internal_dependencies, auth, data_persistence
- `external_dependencies[]`: name, type, description, used_by, optional

It does NOT contain: individual file listings, file contents, README/docs text, test files, CI config, non-component files like SECURITY.md or CHANGELOG.md.

## Files changed

- `src/shesha/analysis/shortcut.py` — add `_CLASSIFIER_PROMPT`, `classify_query()`, modify `try_answer_from_analysis`
- `tests/unit/analysis/test_shortcut_classifier.py` (new) — classifier unit tests

## Test plan

Unit tests with mocked LLM calls:

1. Returns `False` for existence checks
2. Returns `False` for accuracy/verification questions
3. Returns `False` for user doubt signals
4. Returns `False` for file content requests
5. Returns `True` for general architecture questions
6. Returns `True` for dependency questions
7. Returns `True` on LLM exception (graceful fallback)
8. Returns `True` on unparseable LLM output (graceful fallback)

Integration test: when `classify_query` returns `False`, `try_answer_from_analysis` returns `None` without making the shortcut LLM call.
